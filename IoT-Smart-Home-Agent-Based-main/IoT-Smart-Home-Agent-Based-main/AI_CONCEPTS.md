# AI Concepts Used in IoT Smart Home Agent System

## Table of Contents
1. [Agent-Based Architecture](#1-agent-based-architecture)
2. [Natural Language Processing (NLP)](#2-natural-language-processing-nlp)
3. [Speech Recognition (ASR)](#3-speech-recognition-asr)
4. [Large Language Models (LLMs)](#4-large-language-models-llms)
5. [Function Calling / Tool Use](#5-function-calling--tool-use)
6. [Intent Recognition & Classification](#6-intent-recognition--classification)
7. [Reactive Agents](#7-reactive-agents)
8. [Perception-Action Loop](#8-perception-action-loop)
9. [Context-Aware Computing](#9-context-aware-computing)
10. [Multi-Modal AI](#10-multi-modal-ai)

---

## 1. Agent-Based Architecture

### What is an Agent?
An **AI Agent** is an autonomous entity that:
- **Perceives** its environment through sensors
- **Reasons** about what actions to take
- **Acts** upon the environment to achieve goals

### How It's Used in This Project:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SMART HOME AGENT                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  SENSORS (Perception)     â”‚  ACTUATORS (Action)             â”‚
â”‚  â”œâ”€ LDR (Light)           â”‚  â”œâ”€ Night LED                   â”‚
â”‚  â”œâ”€ Ultrasonic (Distance) â”‚  â”œâ”€ Garage Door Servo           â”‚
â”‚  â”œâ”€ PIR (Motion)          â”‚  â”œâ”€ Clothes Servo               â”‚
â”‚  â”œâ”€ Rain Sensor           â”‚  â”œâ”€ Water Pump                  â”‚
â”‚  â”œâ”€ Soil Moisture         â”‚  â”œâ”€ AC, Fan, Heater             â”‚
â”‚  â”œâ”€ Flame Sensor          â”‚  â”œâ”€ Door Lock                   â”‚
â”‚  â”œâ”€ Smoke Sensor          â”‚  â””â”€ Sprinkler, Alarm, etc.      â”‚
â”‚  â”œâ”€ DHT22 (Temp/Humidity) â”‚                                 â”‚
â”‚  â””â”€ Water Level           â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 REASONING (AI Brain)                        â”‚
â”‚  â”œâ”€ AI Language Model for intent parsing                    â”‚
â”‚  â”œâ”€ Rule-based auto mode logic                              â”‚
â”‚  â””â”€ Context-aware decision making                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Properties in This System:
| Property | Implementation |
|----------|---------------|
| **Autonomy** | Auto mode controls devices without human intervention |
| **Reactivity** | Responds to sensor changes in real-time |
| **Pro-activeness** | Anticipates needs (e.g., closes clothes when rain detected) |
| **Social Ability** | Communicates with user via voice commands |

### Code Reference:
```python
# backend/infrastructure/openai_agent.py
class OpenAIIntentParser:
    """
    AI Language Model powered intent parser using function calling.
    Converts natural language to structured device commands.
    """
```

---

## 2. Natural Language Processing (NLP)

### What is NLP?
**Natural Language Processing** enables computers to understand, interpret, and generate human language.

### NLP Tasks in This Project:

#### a) Text Understanding
- Parsing user voice commands like "turn on the lights"
- Understanding synonyms: "lights" = "lamp" = "bulb" = "night_led"
- Handling variations: "switch on", "enable", "activate" â†’ same action

#### b) Intent Extraction
Converting free-form text to structured commands:
```
Input:  "Hey, can you please turn on the lights in the living room?"
Output: {device: "night_led", action: "on"}
```

#### c) Semantic Understanding
```python
# The AI understands context and meaning:
"It's getting dark" â†’ Turns on lights
"It's raining" â†’ Closes clothes servo, window blinds, curtains
"I'm cold" â†’ Turns on heater
"I'm leaving" â†’ Locks door, turns off devices
```

### Code Reference:
```python
# System prompt that guides NLP understanding
SYSTEM_PROMPT = """You are an AI assistant for a smart home IoT system.
Your role is to interpret user voice commands and convert them into device actions.

IMPORTANT ALIASES:
- "lights", "light", "lamp", "bulb" = night_led
- "AC", "air con", "cooling" = air_conditioner
..."""
```

---

## 3. Speech Recognition (ASR)

### What is ASR?
**Automatic Speech Recognition** converts spoken language into text.

### Technology Used: OpenAI Whisper
- State-of-the-art speech recognition model
- Supports multiple languages
- Robust to accents and background noise

### How It Works:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User    â”‚â”€â”€â”€â–¶â”‚ Mobile App  â”‚â”€â”€â”€â–¶â”‚ Whisper API  â”‚â”€â”€â”€â–¶â”‚ Text Output â”‚
â”‚  Speech  â”‚    â”‚ (Recording) â”‚    â”‚ (OpenAI)     â”‚    â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     ğŸ¤              ğŸ“±                 ğŸ¤–                  ğŸ“
```

### Code Reference:
```python
# backend/infrastructure/openai_agent.py
async def transcribe_audio(self, audio_file: Any) -> str:
    """Transcribe audio file using OpenAI Whisper API."""
    response = await self._client.audio.transcriptions.create(
        model="whisper-1",
        file=f,
        language="en"
    )
    return response.text
```

---

## 4. Large Language Models (LLMs)

### What is an LLM?
**Large Language Models** are neural networks trained on vast text data to understand and generate human-like text.

### Model Used: OpenAI Language Model
- Developed by OpenAI
- Large context window (128K tokens)
- Optimized for fast, cost-effective responses
- Supports function calling for structured outputs

### LLM Capabilities Used:
| Capability | Usage in Project |
|------------|-----------------|
| **Text Understanding** | Parsing voice commands |
| **Reasoning** | Deciding which device to control |
| **Context Retention** | Understanding follow-up commands |
| **Structured Output** | Function calling for device commands |

### Why This AI Model?
1. **Fast Response**: Low latency for real-time control
2. **Cost Effective**: Optimized for production use
3. **Function Calling**: Native support for structured outputs
4. **Accuracy**: High accuracy for command interpretation

### Code Reference:
```python
# Creating LLM client
self._client = AsyncOpenAI(api_key=api_key)

# Making LLM call with function calling
response = await self._client.chat.completions.create(
    model="<ai-language-model>",  # OpenAI's optimized model
    messages=messages,
    functions=self.FUNCTIONS,
    function_call="auto",
    temperature=0.1  # Low temperature for consistent outputs
)
```

---

## 5. Function Calling / Tool Use

### What is Function Calling?
**Function Calling** allows LLMs to output structured data that can trigger specific functions in code.

### How It Works:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Command   â”‚â”€â”€â”€â”€â–¶â”‚   AI Model      â”‚â”€â”€â”€â”€â–¶â”‚ Structured JSON  â”‚
â”‚ "turn on fan"  â”‚     â”‚ (with functions)â”‚     â”‚ {device, action} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚ Python Code Execution                â”‚
                              â”‚ control_device("ceiling_fan", "on")  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Defined Functions:
```python
FUNCTIONS = [
    {
        "name": "control_device",
        "description": "Control a specific smart home device",
        "parameters": {
            "type": "object",
            "properties": {
                "device": {
                    "type": "string",
                    "enum": ["night_led", "garage_door", "water_pump", ...]
                },
                "action": {
                    "type": "string",
                    "enum": ["on", "off", "open", "close"]
                }
            }
        }
    },
    {
        "name": "toggle_auto_mode",
        "description": "Enable or disable automatic device control",
        ...
    },
    {
        "name": "get_status",
        "description": "Get current system status and sensor readings",
        ...
    }
]
```

### Benefits:
1. **Type Safety**: Ensures valid device names and actions
2. **Reliability**: No hallucinated device names
3. **Easy Integration**: Direct mapping to hardware commands

---

## 6. Intent Recognition & Classification

### What is Intent Recognition?
**Intent Recognition** identifies the user's goal from their input.

### Intents in This System:
| Intent | Example Commands | Action |
|--------|-----------------|--------|
| `CONTROL_DEVICE` | "turn on lights", "open garage" | Execute device command |
| `TOGGLE_AUTO_MODE` | "enable auto mode", "manual control" | Switch modes |
| `GET_STATUS` | "what's the temperature?", "is it raining?" | Return sensor data |
| `EMERGENCY` | "there's a fire!", "smoke detected" | Trigger alarm |

### Multi-Intent Handling:
```
User: "It's raining, bring the clothes inside and close all windows"

Recognized Intents:
1. control_device(clothes_servo, close)
2. control_device(window_blinds, close)
3. control_device(curtains, close)
```

### Code Flow:
```python
async def parse_intent(self, transcription: str, telemetry: TelemetrySnapshot):
    # 1. Send to LLM with current system state
    response = await self._client.chat.completions.create(...)
    
    # 2. Extract function calls from response
    function_call = response.choices[0].message.function_call
    
    # 3. Parse arguments
    args = json.loads(function_call.arguments)
    
    # 4. Return structured command
    return DeviceCommand(device=args["device"], action=args["action"])
```

---

## 7. Reactive Agents

### What is a Reactive Agent?
A **Reactive Agent** responds to environmental changes without complex reasoning or planning.

### Stimulus-Response Rules (Auto Mode):
```python
# Rule-based reactive behavior in Arduino
if (ldr_value > 500):           # Dark outside
    turn_on(night_led)
    
if (distance >= 5 and distance <= 15):  # Car approaching
    open(garage_door)
    
if (rain_detected):             # Raining
    close(clothes_servo)
    
if (soil_moisture > 900 and water_level_ok):  # Dry soil
    turn_on(water_pump)
    
if (temperature > 28):          # Hot
    turn_on(air_conditioner)
    
if (temperature < 18):          # Cold
    turn_on(heater)
```

### Reactive Architecture:
```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           CONDITION-ACTION RULES        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  IF dark        THEN lights ON          â”‚
        â”‚  IF raining     THEN clothes IN         â”‚
        â”‚  IF car nearby  THEN garage OPEN        â”‚
        â”‚  IF soil dry    THEN pump ON            â”‚
        â”‚  IF hot         THEN AC ON              â”‚
        â”‚  IF fire        THEN alarm ON           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Sensor  â”‚     â”‚ Sensor  â”‚     â”‚ Sensor  â”‚
    â”‚  Input  â”‚     â”‚  Input  â”‚     â”‚  Input  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. Perception-Action Loop

### What is the Perception-Action Loop?
The continuous cycle of **sensing â†’ processing â†’ acting** that enables intelligent behavior.

### Implementation in This Project:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PERCEPTION-ACTION LOOP                        â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚ PERCEIVEâ”‚â”€â”€â”€â–¶â”‚   PROCESS   â”‚â”€â”€â”€â–¶â”‚  DECIDE â”‚â”€â”€â”€â–¶â”‚   ACT   â”‚  â”‚
â”‚   â”‚ Sensors â”‚    â”‚ Read Values â”‚    â”‚ AI/Rulesâ”‚    â”‚ Actuate â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â–²                                                 â”‚       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                         FEEDBACK LOOP                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Timing:
- **Sensor Reading**: Every 1 second
- **Telemetry Broadcast**: Every 1 second via WebSocket
- **Auto Mode Decisions**: Real-time based on sensor thresholds

### Code Reference:
```python
# Continuous telemetry loop
async def _telemetry_reader_loop(self):
    while self._running:
        # PERCEIVE: Read from Arduino
        line = await self._serial.readline()
        
        # PROCESS: Parse telemetry
        telemetry = self._parse_telemetry(line)
        
        # Store for decision making
        self._latest_telemetry = telemetry
        
        await asyncio.sleep(0.1)
```

---

## 9. Context-Aware Computing

### What is Context-Aware Computing?
Systems that adapt their behavior based on the current **context** (environment, user state, history).

### Context Sources in This Project:
| Context Type | Source | Usage |
|--------------|--------|-------|
| **Environmental** | Sensors | Light, temperature, humidity, rain |
| **Temporal** | System clock | Day/night detection |
| **User** | Voice commands | User preferences and requests |
| **Device State** | Actuator feedback | Current on/off status |

### Context-Aware Responses:
```python
# The AI uses context to make intelligent decisions
user_message = f"""
User command: "{transcription}"

Current sensor readings:
- Light level: {telemetry.ldr_value} (higher = darker)
- Temperature: {telemetry.temperature}Â°C
- Humidity: {telemetry.humidity}%
- Motion detected: {telemetry.motion_detected}
- Rain detected: {telemetry.rain_detected}
- Auto mode: {telemetry.auto_mode}
"""

# AI can now make context-aware decisions:
# "make it comfortable" â†’ checks temp â†’ turns on AC or heater
# "secure the house" â†’ locks doors, closes windows, enables alarm
```

---

## 10. Multi-Modal AI

### What is Multi-Modal AI?
AI systems that process multiple types of input (text, speech, images, sensor data).

### Modalities in This Project:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MULTI-MODAL INPUTS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   ğŸ¤ AUDIO          ğŸ“Š SENSOR DATA       ğŸ“± UI CONTROLS    â”‚
â”‚   â”œâ”€ Voice          â”œâ”€ Temperature       â”œâ”€ Toggle buttons â”‚
â”‚   â”‚  commands       â”œâ”€ Humidity          â”œâ”€ Sliders        â”‚
â”‚   â”‚                 â”œâ”€ Light level       â””â”€ Manual control â”‚
â”‚   â”‚                 â”œâ”€ Motion            â”‚                 â”‚
â”‚   â–¼                 â”œâ”€ Rain              â”‚                 â”‚
â”‚   Whisper ASR       â”œâ”€ Smoke             â”‚                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”œâ”€ Flame             â”‚                 â”‚
â”‚   â”‚                 â””â”€ Distance          â”‚                 â”‚
â”‚   â–¼                        â”‚             â”‚                 â”‚
â”‚   Text                     â–¼             â–¼                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â–¼                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚              â”‚   AI Model   â”‚                               â”‚
â”‚              â”‚  REASONING   â”‚                               â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                     â”‚                                       â”‚
â”‚                     â–¼                                       â”‚
â”‚              UNIFIED RESPONSE                               â”‚
â”‚              (Device Commands)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Summary: AI Techniques Used

| AI Concept | Technology/Method | Purpose |
|------------|-------------------|---------|
| Agent Architecture | Custom implementation | Autonomous control |
| NLP | OpenAI LLM | Command understanding |
| Speech Recognition | OpenAI Whisper | Voice-to-text |
| LLM | OpenAI LLM | Reasoning & decisions |
| Function Calling | OpenAI Functions | Structured outputs |
| Intent Recognition | LLM + Functions | Command classification |
| Reactive Agent | Rule-based system | Auto mode control |
| Perception-Action | Sensor-Actuator loop | Real-time response |
| Context-Awareness | Telemetry integration | Smart decisions |
| Multi-Modal AI | Audio + Sensors + UI | Multiple input types |

---

## Viva Questions & Answers

### Q1: What type of AI agent is this system?
**A:** This is a **Hybrid Agent** combining:
- **Reactive Agent**: Rule-based auto mode for immediate responses
- **Cognitive Agent**: LLM-based reasoning for voice commands

### Q2: How does the system understand voice commands?
**A:** Two-step process:
1. **Speech-to-Text**: OpenAI Whisper converts audio to text
2. **Intent Parsing**: AI Language Model extracts device and action using function calling

### Q3: What is function calling and why is it used?
**A:** Function calling allows the LLM to output structured JSON instead of free text. This ensures:
- Valid device names (from predefined enum)
- Valid actions (on/off/open/close)
- Easy integration with hardware control code

### Q4: How does auto mode work?
**A:** Auto mode uses **condition-action rules**:
- Sensors continuously read environmental data
- Predefined thresholds trigger automatic responses
- Example: LDR > 500 (dark) â†’ Turn on lights

### Q5: What makes this system "intelligent"?
**A:** Multiple AI capabilities:
- Understanding natural language variations
- Context-aware decision making
- Learning user intent from ambiguous commands
- Multi-device coordination for complex requests

### Q6: How is real-time communication achieved?
**A:** Using **WebSocket** protocol:
- Bidirectional communication
- Telemetry pushed every 1 second
- Instant command execution feedback

### Q7: What happens if the AI doesn't understand a command?
**A:** The system returns a `clarification_needed` status with a question asking the user to rephrase or provide more details.

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MOBILE APP (React Native)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ Voice Input â”‚  â”‚  Dashboard  â”‚  â”‚   Controls  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                â”‚                â”‚
          â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND (FastAPI + Python)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Whisper    â”‚  â”‚  AI Model    â”‚  â”‚   WebSocket  â”‚              â”‚
â”‚  â”‚  (ASR)       â”‚  â”‚  (Intent)    â”‚  â”‚  (Real-time) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â”‚                                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚  Use Cases    â”‚                               â”‚
â”‚                    â”‚  (Business    â”‚                               â”‚
â”‚                    â”‚   Logic)      â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ARDUINO (Hardware)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚      SENSORS        â”‚    â”‚     ACTUATORS       â”‚                â”‚
â”‚  â”‚  â”œâ”€ LDR             â”‚    â”‚  â”œâ”€ LEDs            â”‚                â”‚
â”‚  â”‚  â”œâ”€ Ultrasonic      â”‚    â”‚  â”œâ”€ Servos          â”‚                â”‚
â”‚  â”‚  â”œâ”€ PIR             â”‚    â”‚  â”œâ”€ Relay (Pump)    â”‚                â”‚
â”‚  â”‚  â”œâ”€ Rain            â”‚    â”‚  â”œâ”€ Buzzer          â”‚                â”‚
â”‚  â”‚  â”œâ”€ DHT22           â”‚    â”‚  â””â”€ ...             â”‚                â”‚
â”‚  â”‚  â””â”€ ...             â”‚    â”‚                     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*This document covers all AI concepts used in the IoT Smart Home Agent System for viva preparation.*
